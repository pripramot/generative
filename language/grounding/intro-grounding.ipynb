{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Getting Started with Grounding in Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/grounding/intro-grounding.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/grounding/intro-grounding.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/grounding/intro-grounding.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24743cf4a1e1"
   },
   "source": [
    "**_NOTE_**: This notebook has been tested in the following environment:\n",
    "\n",
    "* Python version = 3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Grounding in Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/grounding/overview) lets you use language models (e.g., [`text-bison` and `chat-bison`](https://cloud.google.com/vertex-ai/docs/generative-ai/language-model-overview)) to generate content grounded in your own documents and data. This capability lets the model access information at runtime that goes beyond its training data. By grounding model responses in Google Search results or data stores within [Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction), LLMs that are grounded in data can produce more accurate, up-to-date, and relevant responses.\n",
    "\n",
    "Grounding provides the following benefits:\n",
    "\n",
    "- Reduces model hallucinations (instances where the model generates content that isn't factual)\n",
    "- Anchors model responses to specific information, documents, and data sources\n",
    "- Enhances the trustworthiness, accuracy, and applicability of the generated content\n",
    "\n",
    "In the context of grounding in Vertex AI, you can configure two different sources of grounding:\n",
    "\n",
    "1. Google Search results for data that is publicly available and indexed\n",
    "1. [Data stores in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest), which can include your own data in the form of website data, unstructured data, or structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to:\n",
    "\n",
    "- Generate LLM text and chat model responses grounded in Google Search results\n",
    "- Compare the results of ungrounded LLM responses with grounded LLM responses\n",
    "- Create and use a data store in Vertex AI Search to ground responses in custom documents and data\n",
    "- Generate LLM text and chat model responses grounded in Vertex AI Search results\n",
    "- Use the asynchronous text and chat models APIs with grounding\n",
    "\n",
    "This tutorial uses the following Google Cloud AI services and resources:\n",
    "\n",
    "- Vertex AI\n",
    "- Vertex AI Search and Conversation\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Configuring the LLM and prompt for various examples\n",
    "- Sending example prompts to generative text and chat models in Vertex AI\n",
    "- Setting up a data store in Vertex AI Search with your own data\n",
    "- Sending example prompts with various levels of grounding (no grounding, web grounding, data store grounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "1. Enable the [Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com) and [Vertex AI Search and Conversation API](https://console.cloud.google.com/flows/enableapi?apiid=discoveryengine.googleapis.com).\n",
    "1. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet google-cloud-aiplatform==1.38.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58707a750154"
   },
   "source": [
    "Restart the kernel after installing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f200f10a1da3"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### Configure your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project ID\n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "### Configure your region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBCra4QMA2wR"
   },
   "source": [
    "### Authenticate your Google Cloud account\n",
    "\n",
    "If you are running this notebook on Google Colab, you will need to authenticate your environment. To do this, run the new cell below. This step is not required if you are using Vertex AI Workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "603adbbf0532"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel, ChatModel, GroundingSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the generative text and chat models from Vertex AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "chat_model = ChatModel.from_pretrained(\"chat-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Grounding with Google Search results\n",
    "\n",
    "In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a Google Search. You'll ask a question about a recent hardware release from the Google Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = (\n",
    "    \"What are the price, available colors, and storage size options of a Pixel Tablet?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation without grounding\n",
    "\n",
    "Make a prediction request to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(The Pixel Tablet will be available in three colors: Stormy Black, Kinda Coral, and Sorta Seafoam. It will have 128GB and 256GB storage options. The price has not yet been announced.,\n",
       " GroundingMetadata(citations=[], search_queries=[]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = text_model.predict(PROMPT)\n",
    "\n",
    "response, response.grounding_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation grounded in Google Search results\n",
    "\n",
    "Now you can add the `grounding_source` keyword arg with a grounding source of `GroundingSource.WebSearch()` to instruct the LLM to first perform a Google Search with the prompt, then construct an answer based on the web search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(The Pixel Tablet starts at $499 in the US, £599 in the UK, €679 throughout selected European regions, and CAD $699 in Canada. The tablet comes in three colors: Porcelain (white), Rose (pink), and Hazel (gray). The Pixel Tablet is available in two storage size options: 8GB/128GB and 8GB/256GB.,\n",
       " GroundingMetadata(citations=[GroundingCitation(start_index=0, end_index=128, url='https://www.androidauthority.com/google-pixel-tablet-3163922/', title=None, license=None, publication_date=None), GroundingCitation(start_index=129, end_index=212, url='https://www.androidpolice.com/google-pixel-tablet/', title=None, license=None, publication_date=None), GroundingCitation(start_index=213, end_index=296, url='https://priceinall.com/product/google-pixel-tablet/', title=None, license=None, publication_date=None)], search_queries=['Pixel Tablet price, colors, and storage size options?']))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grounding_source = GroundingSource.WebSearch()\n",
    "\n",
    "response = text_model.predict(\n",
    "    PROMPT,\n",
    "    grounding_source=grounding_source,\n",
    ")\n",
    "\n",
    "response, response.grounding_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the response without grounding only has outdated information from the LLM about the potential release date of the Pixel tablet. Whereas the response that was grounded in web search results contains the most up to date information from web search results that are returned as part of the LLM with grounding request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Grounding with custom documents and data\n",
    "\n",
    "In this example, you'll compare LLM responses with no grounding with responses that are grounded in the [results of a data store in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest). You'll ask a question about a GoogleSQL query to create an [object table in BigQuery](https://cloud.google.com/bigquery/docs/object-table-introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a data store in Vertex AI Search\n",
    "\n",
    "Follow the steps in the [Vertex AI Search getting started documentation](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app_for_website_data) to create a data store in Vertex AI Search with sample data. In this example, you'll use a website-based data store that contains content from the Google Cloud website, including documentation.\n",
    "\n",
    "Once you've created a data store, obtain the Data Store ID and input it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_STORE_ID = \"your-data-store-id_1234567890123\"  # Replace this with your data store ID from Vertex AI Search\n",
    "DATA_STORE_REGION = \"global\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can ask a question about object tables in BigQuery and when to use them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"When should I use an object table in BigQuery? And how does it store data?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation without grounding\n",
    "\n",
    "Make a prediction request to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GroundingMetadata(citations=[], search_queries=[]),\n",
       " Object tables are a type of table in BigQuery that can store data in a variety of formats, including JSON, Avro, Parquet, and ORC. They are useful when you need to store data that is not natively supported by BigQuery, such as images or videos.\n",
       "\n",
       "Object tables are stored in a different way than regular BigQuery tables. Regular BigQuery tables are stored in columnar format, which means that the data is stored in rows, with each column being a separate data field. Object tables, on the other hand, are stored in row-oriented format, which means that the data is stored in rows)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = text_model.predict(PROMPT)\n",
    "\n",
    "response.grounding_metadata, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation grounded in Vertex AI Search results\n",
    "\n",
    "Now we can add the `grounding_source` keyword arg with a grounding source of `GroundingSource.VertexAISearch()` to instruct the LLM to first perform a search within your custom data store, then construct an answer based on the relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GroundingMetadata(citations=[GroundingCitation(start_index=0, end_index=65, url='https://cloud.google.com/bigquery/docs/object-table-introduction', title=None, license=None, publication_date=None)], search_queries=['When should I use an object table in BigQuery?']),\n",
       " Object tables let you analyze unstructured data in Cloud Storage. You can perform analysis with remote functions or perform inference by using BigQuery ML, and you can also use object tables as input to BigQuery ML models.\n",
       "\n",
       "Object tables store data in Cloud Storage as files. The files can be of any type, and they can be stored in any location in Cloud Storage.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grounding_source = GroundingSource.VertexAISearch(\n",
    "    data_store_id=DATA_STORE_ID, location=DATA_STORE_REGION\n",
    ")\n",
    "\n",
    "response = text_model.predict(\n",
    "    PROMPT,\n",
    "    grounding_source=grounding_source,\n",
    ")\n",
    "\n",
    "response.grounding_metadata, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the response without grounding only has limited information from the LLM about object tables in BigQuery that might not be accurate. Whereas the response that was grounded in Vertex AI Search results contains the most up to date information about object tables based on documents returned from the Google Cloud documentation about BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Grounded chat responses\n",
    "\n",
    "You can also use grounding when working with chat models in Vertex AI. In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a Google Search and a data store in Vertex AI Search.\n",
    "\n",
    "You'll ask a question about Vertex AI and a follow up question about managed datasets in Vertex AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"What are managed datasets in Vertex AI?\"\n",
    "PROMPT_FOLLOWUP = \"What types of data can I use\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat session without grounding\n",
    "\n",
    "Start a chat session and send messages to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundingMetadata(citations=[], search_queries=[])\n",
      "Managed datasets in Vertex AI Managed datasets are a fully managed service that provides a simple and scalable way to store and manage your data. They are built on top of Google Cloud Storage and BigQuery, and they provide a number of features that make it easy to work with your data, including:\n",
      "\n",
      "* Automatic schema discovery and validation\n",
      "* Automatic partitioning and replication\n",
      "* Built-in support for machine learning models\n",
      "* Integration with other Google Cloud services\n",
      "\n",
      "Managed datasets are a great option for organizations that want to store and manage their data in a scalable and cost-effective way. They are also a good choice for organizations that want to use machine learning models to analyze their data.\n",
      "GroundingMetadata(citations=[], search_queries=[])\n",
      "Managed datasets can store any type of data, including structured, semi-structured, and unstructured data. They can also store data from a variety of sources, including Google Cloud Storage, BigQuery, and other external sources.\n"
     ]
    }
   ],
   "source": [
    "chat = chat_model.start_chat()\n",
    "\n",
    "response = chat.send_message(PROMPT)\n",
    "print(response.grounding_metadata)\n",
    "print(response.text)\n",
    "\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "print(response.grounding_metadata)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat session grounded in Google Search results\n",
    "\n",
    "Now you can add the `grounding_source` keyword arg with a grounding source of `GroundingSource.WebSearch()` to instruct the chat model to first perform a Google Search with the prompt, then construct an answer based on the web search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundingMetadata(citations=[], search_queries=[])\n",
      "Managed datasets in Vertex AI are a way to store and manage your data for machine learning (ML) models. They are fully managed, which means that Google takes care of the underlying infrastructure and storage, so you can focus on building your models. Managed datasets also support versioning, so you can track changes to your data over time.\n",
      "GroundingMetadata(citations=[], search_queries=[])\n",
      "You can use any type of data that can be stored in a Google Cloud Storage bucket, including tabular data, image data, and text data.\n"
     ]
    }
   ],
   "source": [
    "chat = chat_model.start_chat()\n",
    "grounding_source = GroundingSource.WebSearch()\n",
    "\n",
    "response = chat.send_message(\n",
    "    PROMPT,\n",
    "    grounding_source=grounding_source,\n",
    ")\n",
    "\n",
    "response = chat.send_message(PROMPT)\n",
    "print(response.grounding_metadata)\n",
    "print(response.text)\n",
    "\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "print(response.grounding_metadata)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat session grounded in Vertex AI Search results\n",
    "\n",
    "Now you can add the `grounding_source` keyword arg with a grounding source of `GroundingSource.VertexAISearch()` to instruct the chat model to first perform a search within your custom data store, then construct an answer based on the relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundingMetadata(citations=[], search_queries=[])\n",
      "Managed datasets in Vertex AI are a way to store and manage your data for machine learning models. They are fully managed, which means that Google takes care of the underlying infrastructure and storage, so you can focus on building your models. Managed datasets also support versioning, so you can track changes to your data over time.\n",
      "GroundingMetadata(citations=[], search_queries=[])\n",
      "You can use any type of data that can be stored in a Google Cloud Storage bucket, including tabular data, image data, and text data.\n"
     ]
    }
   ],
   "source": [
    "chat = chat_model.start_chat()\n",
    "grounding_source = GroundingSource.VertexAISearch(\n",
    "    data_store_id=DATA_STORE_ID, location=DATA_STORE_REGION\n",
    ")\n",
    "\n",
    "response = chat.send_message(\n",
    "    PROMPT,\n",
    "    grounding_source=grounding_source,\n",
    ")\n",
    "\n",
    "response = chat.send_message(PROMPT)\n",
    "print(response.grounding_metadata)\n",
    "print(response.text)\n",
    "\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "print(response.grounding_metadata)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Grounded async text and chat responses\n",
    "\n",
    "You can also use grounding in Vertex AI when working with the asynchronous APIs for the text and chat models. In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a data store in Vertex AI Search.\n",
    "\n",
    "You'll ask a question about different services available in Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"What are the different types of databases available in Google Cloud?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async text generation grounded in Google Search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GroundingMetadata(citations=[GroundingCitation(start_index=134, end_index=172, url='https://cloud.google.com/blog/topics/developers-practitioners/your-google-cloud-database-options-explained', title=None, license=None, publication_date=None)], search_queries=['What are the different types of databases available in Google Cloud?']),\n",
       " Google Cloud Database offers fully managed solutions both for relational and non relational databases with high security features. · Relational : Cloud SQL and AlloyDB. · Non-relational : Cloud Spanner, Cloud Bigtable, Cloud Firestore, Cloud Datastore, Cloud Memorystore for Redis, Cloud Memorystore for Memcached, Cloud SQL for PostgreSQL, Cloud SQL for MySQL, Cloud SQL for SQL Server.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grounding_souce = GroundingSource.WebSearch()\n",
    "\n",
    "response = await text_model.predict_async(\n",
    "    PROMPT,\n",
    "    grounding_source=grounding_souce,\n",
    ")\n",
    "\n",
    "response.grounding_metadata, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async text generation grounded in Vertex AI Search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GroundingMetadata(citations=[], search_queries=['What are the different types of databases available in Google Cloud?']),\n",
       " Google Cloud offers a variety of databases to meet the needs of your business. You can choose from relational databases, NoSQL databases, in-memory databases, and document databases.\n",
       "\n",
       "Relational databases are the most common type of database. They store data in tables, which are organized into rows and columns. Relational databases are good for storing structured data, such as customer records or product information.\n",
       "\n",
       "NoSQL databases are a newer type of database that are not based on the relational model. NoSQL databases are good for storing unstructured data, such as social media data or sensor data.\n",
       "\n",
       "In-memory databases store data in RAM)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grounding_souce = GroundingSource.VertexAISearch(\n",
    "    data_store_id=DATA_STORE_ID, location=DATA_STORE_REGION\n",
    ")\n",
    "\n",
    "response = await text_model.predict_async(\n",
    "    PROMPT,\n",
    "    grounding_source=grounding_souce,\n",
    ")\n",
    "\n",
    "response.grounding_metadata, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async chat session grounded in Google Search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GroundingMetadata(citations=[], search_queries=['What are the different types of databases available in Google Cloud?']),\n",
       " Google Cloud offers a wide range of databases to meet the needs of your business. These include relational databases, NoSQL databases, and in-memory databases.\n",
       "\n",
       "Relational databases are designed to store data in tables, with each row representing a record and each column representing a field. They are well-suited for applications that require structured data, such as customer relationship management (CRM) systems and enterprise resource planning (ERP) systems.\n",
       "\n",
       "NoSQL databases are designed to store data in a more flexible way than relational databases. They do not require data to be stored in tables, and they can support different types of data, such as text, images, and videos. NoSQL databases are well-suited for applications that require high performance and scalability, such as web applications and mobile applications.\n",
       "\n",
       "In-memory databases store data in RAM rather than on disk. This makes them very fast, but they also have a limited capacity. In-memory databases are well-suited for applications that require real-time processing of data, such as financial trading systems and gaming applications.\n",
       "\n",
       "To learn more about the different types of databases available in Google Cloud, please visit the following resources:\n",
       "\n",
       "* [Google Cloud Databases](https://cloud.google.com/products/databases)\n",
       "* [Google Cloud Database documentation](https://cloud.google.com/databases/docs/)\n",
       "* [Google Cloud Database pricing](https://cloud.google.com/databases/pricing))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = chat_model.start_chat()\n",
    "\n",
    "grounding_source = GroundingSource.WebSearch()\n",
    "response = await chat.send_message_async(\n",
    "    PROMPT,\n",
    "    grounding_source=grounding_source,\n",
    ")\n",
    "\n",
    "response.grounding_metadata, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async chat session grounded in Vertex AI Search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GroundingMetadata(citations=[], search_queries=['What are the different types of databases available in Google Cloud?']),\n",
       " Google Cloud offers a wide range of database options to meet the needs of your business. These include relational databases, NoSQL databases, in-memory databases, and document databases.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = chat_model.start_chat()\n",
    "\n",
    "grounding_source = GroundingSource.VertexAISearch(\n",
    "    data_store_id=DATA_STORE_ID, location=DATA_STORE_REGION\n",
    ")\n",
    "response = await chat.send_message_async(\n",
    "    PROMPT,\n",
    "    grounding_source=grounding_source,\n",
    ")\n",
    "\n",
    "response.grounding_metadata, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To avoid incurring charges to your Google Cloud account for the resources used in this notebook, follow these steps:\n",
    "\n",
    "1. To avoid unnecessary Google Cloud charges, use the [Google Cloud console](https://console.cloud.google.com/) to delete your project if you do not need it. Learn more in the Google Cloud documentation for [managing and deleting your project](https://cloud.google.com/resource-manager/docs/creating-managing-projects).\n",
    "1. If you used an existing Google Cloud project, delete the resources you created to avoid incurring charges to your account. For more information, refer to the documentation to [Delete data from a data store in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/delete-datastores), then delete your data store.\n",
    "1. Disable the [Vertex AI Search and Conversation API](https://pantheon.corp.google.com/apis/api/discoveryengine.googleapis.com) and [Vertex AI API](https://pantheon.corp.google.com/apis/api/aiplatform.googleapis.com) in the Google Cloud Console."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
